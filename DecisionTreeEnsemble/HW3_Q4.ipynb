{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "41ByKBEm2FFE"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "80eGYDq72Icw"
      },
      "outputs": [],
      "source": [
        "class SimpleMultiClassBoosting(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, base_estimator=None, n_estimators=50):\n",
        "        self.base_estimator = base_estimator if base_estimator is not None else DecisionTreeClassifier(max_depth=1)\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learners = []\n",
        "        self.learner_weights = []\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Convert labels to [0, n_classes-1]\n",
        "        Y = self.label_encoder.fit_transform(y)\n",
        "        n_classes = len(np.unique(Y))\n",
        "        # Initialize weights uniformly\n",
        "        n_samples = X.shape[0]\n",
        "        self.weights = (1/n_samples) * np.ones(n_samples, dtype=float)\n",
        "        for _ in range(self.n_estimators):\n",
        "            learner = DecisionTreeClassifier(max_depth=1)\n",
        "            learner.fit(X, Y, sample_weight=self.weights)\n",
        "            pred = learner.predict(X)\n",
        "            missClassified = pred != y\n",
        "            learner_error = np.sum(self.weights[missClassified]) / np.sum(self.weights)\n",
        "            # Compute weighted error rate (misclassification rate)\n",
        "            learner_weight = np.log((1-learner_error) / learner_error) + np.log(n_classes - 1)\n",
        "            # Compute learner weight using SAMME algorithm\n",
        "\n",
        "            if learner_error >= 1 - (1 / n_classes):\n",
        "                break\n",
        "\n",
        "            # Increase the weights of misclassified samples\n",
        "            for idx in range(n_samples):\n",
        "                if missClassified[idx] == True:\n",
        "                    self.weights[idx] *= np.exp(learner_weight)    \n",
        "            self.weights /= np.sum(self.weights)    \n",
        "            # Save the current learner\n",
        "            self.learners.append(learner)\n",
        "            self.learner_weights.append(learner_weight)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Collect predictions from each learner\n",
        "\n",
        "        # Weighted vote for each sample's prediction across all learners\n",
        "\n",
        "        # Final prediction is the one with the highest weighted vote\n",
        "\n",
        "        # Convert back to original class labels\n",
        "        predictionsOfLearners = []\n",
        "        for learner in self.learners:\n",
        "            predictionsOfLearners.append(learner.predict(X))\n",
        "        predictionsOfLearners = np.array(predictionsOfLearners)\n",
        "        prediction = np.empty(X.shape[0])        \n",
        "        for i in range(X.shape[0]):\n",
        "            labels = np.unique(predictionsOfLearners[:, i])\n",
        "            votes = {label : 0 for label in labels}\n",
        "            for j in range(len(predictionsOfLearners[:, i])):\n",
        "                for label in labels:\n",
        "                    if predictionsOfLearners[j, i] == label:\n",
        "                        votes[label] += self.learner_weights[j]\n",
        "            finalPrediction = max(votes, key=votes.get)\n",
        "            prediction[i] = self.label_encoder.inverse_transform(np.array([finalPrediction]))\n",
        "        return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "3                4.6               3.1                1.5               0.2   \n",
              "4                5.0               3.6                1.4               0.2   \n",
              "\n",
              "   target  \n",
              "0     0.0  \n",
              "1     0.0  \n",
              "2     0.0  \n",
              "3     0.0  \n",
              "4     0.0  "
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df.iloc[:, :-1].to_numpy(), df.iloc[:, -1].to_numpy(), test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = SimpleMultiClassBoosting()\n",
        "m.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 0., 2., 1., 1., 0., 1., 2., 1., 1., 2., 0., 0., 0., 0., 1., 2.,\n",
              "       1., 1., 2., 0., 2., 0., 2., 2., 2., 2., 2., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 2., 1., 0., 0., 0., 2., 1., 1., 0., 0.])"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction = m.predict(X_test)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.3017369730918267, 2.114250946345696, 2.4361903096894206, 2.6001291918124525, 2.105163395441564, 1.6480070039057666, 2.014188780803626, 1.7398419334069946, 2.4093065069579587, 1.9564666410141864, 1.1076657447143285, 1.8142058424030298, 2.0023753103226927, 1.626581259630758, 1.6524999592072571, 1.819583010804596, 1.5679125249855816, 1.682873939578077, 1.8018571731946804, 1.4086633586172383, 1.9371166741691925, 1.7102962259830043, 1.131127046262888, 1.650648363172479, 1.600562850160947, 1.7366014772186413, 1.8453542583246687, 1.5451650715319487, 1.9992195889999356, 1.5533313672483562, 1.8302788893076096, 1.5716059543635796, 1.7916874972003147, 1.571902237661443, 1.472260463269306, 1.5767988870923795, 1.6304574666252014, 1.3247744008431108, 1.4931539072445987, 1.6995581922250098, 1.68096475031206, 1.4266263810163229, 1.7257834743329088, 1.498428479204587, 1.580295225195597, 1.7014079894377163, 1.6093806022458237, 1.6011434436341658, 1.6376034800293464, 1.6164216788635986]\n"
          ]
        }
      ],
      "source": [
        "print(m.learner_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00        19\n",
            "         1.0       1.00      1.00      1.00        13\n",
            "         2.0       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, prediction))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
