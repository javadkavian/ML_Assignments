{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "41ByKBEm2FFE"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "80eGYDq72Icw"
      },
      "outputs": [],
      "source": [
        "class SimpleMultiClassBoosting(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, base_estimator=None, n_estimators=50):\n",
        "        self.base_estimator = base_estimator if base_estimator is not None else DecisionTreeClassifier(max_depth=1)\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learners = np.empty(n_estimators, dtype=object)\n",
        "        self.learner_weights = np.empty(n_estimators, dtype=float)\n",
        "        self.samples_weights = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    # def fit(self, X, y):\n",
        "    #     Y = self.label_encoder.fit_transform(y=y)\n",
        "    #     n_classes = len(np.unique(Y))\n",
        "    #     indexes = np.arange(X.shape[0])\n",
        "    #     self.samples_weights = (1/X.shape[0]) * np.ones(X.shape[0] ,dtype=float)\n",
        "    #     for i in range(self.n_estimators):\n",
        "    #         learner = self.base_estimator\n",
        "    #         learner.fit(X, Y)\n",
        "    #         self.learners[i] = learner\n",
        "    #         missClassifiedIndexes = []\n",
        "    #         predictions = learner.predict(X=X)\n",
        "    #         for j in range(X.shape[0]):\n",
        "    #             if predictions[j] != Y[j]:\n",
        "    #                 missClassifiedIndexes.append(j)\n",
        "    #         learner_error = (np.sum(self.samples_weights[missClassifiedIndexes])) / np.sum(self.samples_weights)\n",
        "    #         learner_rate = 0\n",
        "    #         if learner_error == 0:\n",
        "    #             learner_rate = np.inf\n",
        "    #         else:            \n",
        "    #             learner_rate = np.log((1-learner_error) / learner_error) + np.log(n_classes - 1)\n",
        "    #         if learner_error >= 1 - (1 / n_classes):\n",
        "    #             learner_rate = 0\n",
        "    #         self.learner_weights[i] = learner_rate \n",
        "    #         for idx in missClassifiedIndexes:\n",
        "    #             self.samples_weights[idx] *= self.samples_weights[idx]*np.exp(learner_rate)\n",
        "    #         self.samples_weights /= np.sum(self.samples_weights)\n",
        "    def fit(self, X, y):\n",
        "        Y = self.label_encoder.fit_transform(y=y)\n",
        "        n_classes = len(np.unique(Y))\n",
        "        indexes = np.arange(X.shape[0])\n",
        "        self.samples_weights = (1/X.shape[0]) * np.ones(X.shape[0], dtype=float)\n",
        "        for i in range(self.n_estimators):\n",
        "            learner = self.base_estimator\n",
        "            # training_indexes = np.array(rd.choices(indexes, weights=self.samples_weights, k=X.shape[0]))\n",
        "            # sx = X[training_indexes]\n",
        "            # sy = Y[training_indexes]\n",
        "            # uy = np.unique(sy)\n",
        "            \n",
        "            # # if uy.shape[0] < n_classes:\n",
        "            #     # unseen = list(set(np.unique(Y)) - set(uy))\n",
        "            #     # for u in unseen:\n",
        "            #         # ui = rd.choices(np.where(Y == u)[0], k=1)\n",
        "            #         # sx = np.vstack([sx, X[ui]])\n",
        "            #         # sy = np.hstack([sy, Y[ui]])\n",
        "            # # \n",
        "            learner.fit(X, Y)\n",
        "            self.learners[i] = learner\n",
        "            \n",
        "            predictions = learner.predict(X)\n",
        "            misclassified = predictions != Y\n",
        "            learner_error = np.sum(self.samples_weights[misclassified]) / np.sum(self.samples_weights)\n",
        "            \n",
        "            learner_rate = np.log((1 - learner_error) / learner_error) + np.log(n_classes - 1)\n",
        "            if learner_error >= 1 - 1/n_classes:\n",
        "                learner_rate = 0\n",
        "            # if learner_error == 0:\n",
        "                # learner_rate = np.inf\n",
        "            # else:\n",
        "                # learner_rate = np.log((1 - learner_error) / learner_error) + np.log(n_classes - 1)\n",
        "            \n",
        "            self.learner_weights[i] = learner_rate\n",
        "            \n",
        "            if learner_error < 1/n_classes:\n",
        "                for idx in range(X.shape[0]):\n",
        "                    self.samples_weights[idx] *= np.exp(learner_rate) if misclassified[idx] else 1.0\n",
        "            # for j in misclassified:\n",
        "            #     self.samples_weights[j] *= np.exp(learner_rate)\n",
        "            \n",
        "            self.samples_weights /= np.sum(self.samples_weights)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictionsOfLearners = []\n",
        "        for learner in self.learners:\n",
        "            if learner != None:\n",
        "                predictionsOfLearners.append(learner.predict(X))\n",
        "        predictionsOfLearners = np.array(predictionsOfLearners)\n",
        "        prediction = np.empty(X.shape[0])        \n",
        "        for i in range(X.shape[0]):\n",
        "            labels = np.unique(predictionsOfLearners[:, i])\n",
        "            votes = {label : 0 for label in labels}\n",
        "            for j in range(len(predictionsOfLearners[:, i])):\n",
        "                for label in labels:\n",
        "                    if predictionsOfLearners[j, i] == label:\n",
        "                        votes[label] += self.learner_weights[j]\n",
        "            finalPrediction = max(votes, key=votes.get)\n",
        "            prediction[i] = self.label_encoder.inverse_transform(np.array([finalPrediction]))\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "3                4.6               3.1                1.5               0.2   \n",
              "4                5.0               3.6                1.4               0.2   \n",
              "\n",
              "   target  \n",
              "0     0.0  \n",
              "1     0.0  \n",
              "2     0.0  \n",
              "3     0.0  \n",
              "4     0.0  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df.iloc[:, :-1].to_numpy(), df.iloc[:, -1].to_numpy(), test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = SimpleMultiClassBoosting()\n",
        "m.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction = m.predict(X_test)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.42403469e+00 2.66453526e-15 2.66453526e-15 2.66453526e-15\n",
            " 2.66453526e-15 2.66453526e-15 2.66453526e-15 2.66453526e-15\n",
            " 2.66453526e-15 2.66453526e-15 2.66453526e-15 2.66453526e-15\n",
            " 2.66453526e-15 2.66453526e-15 2.66453526e-15 2.66453526e-15\n",
            " 2.66453526e-15 2.66453526e-15 2.66453526e-15 2.66453526e-15\n",
            " 2.66453526e-15 2.66453526e-15 2.66453526e-15 2.66453526e-15\n",
            " 2.66453526e-15 2.66453526e-15 2.66453526e-15 2.66453526e-15\n",
            " 2.66453526e-15 2.66453526e-15 2.66453526e-15 2.66453526e-15\n",
            " 2.66453526e-15 2.66453526e-15 2.66453526e-15 2.66453526e-15\n",
            " 2.66453526e-15 2.66453526e-15 2.66453526e-15 2.66453526e-15\n",
            " 2.66453526e-15 2.66453526e-15 2.66453526e-15 2.66453526e-15\n",
            " 2.66453526e-15 2.66453526e-15 2.66453526e-15 2.66453526e-15\n",
            " 2.66453526e-15 2.66453526e-15]\n"
          ]
        }
      ],
      "source": [
        "print(m.learner_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00        10\n",
            "         1.0       0.45      1.00      0.62         9\n",
            "         2.0       0.00      0.00      0.00        11\n",
            "\n",
            "    accuracy                           0.63        30\n",
            "   macro avg       0.48      0.67      0.54        30\n",
            "weighted avg       0.47      0.63      0.52        30\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\javadpsk\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\javadpsk\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\javadpsk\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00        10\n",
            "         1.0       1.00      1.00      1.00         9\n",
            "         2.0       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "a = DecisionTreeClassifier(max_depth=3)\n",
        "a.fit(X_train, Y_train)\n",
        "pred = a.predict(X_test)\n",
        "print(classification_report(Y_test, pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
