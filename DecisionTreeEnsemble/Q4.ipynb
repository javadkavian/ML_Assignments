{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "41ByKBEm2FFE"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "80eGYDq72Icw"
      },
      "outputs": [],
      "source": [
        "class SimpleMultiClassBoosting(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, base_estimator=None, n_estimators=50):\n",
        "        self.base_estimator = base_estimator if base_estimator is not None else DecisionTreeClassifier(max_depth=1)\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learners = np.empty(n_estimators, dtype=object)\n",
        "        self.learner_weights = np.empty(n_estimators, dtype=float)\n",
        "        self.samples_weights = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Convert labels to [0, n_classes-1]\n",
        "        Y = self.label_encoder.fit_transform(y=y)\n",
        "        n_classes = len(np.unique(Y))\n",
        "        indexes = np.arange(X.shape[0])\n",
        "        # Initialize weights uniformly\n",
        "        self.samples_weights = (1/X.shape[0]) * np.ones(X.shape[0] ,dtype=float)\n",
        "        for i in range(self.n_estimators):\n",
        "            self.learners[i] = self.base_estimator\n",
        "            training_indexes = np.random.choice(indexes, indexes.shape[0], replace=True, p=self.samples_weights)\n",
        "            self.learners[i].fit(X[training_indexes], Y[training_indexes])\n",
        "            # Compute weighted error rate (misclassification rate)\n",
        "            missClassifiedIndexes = []\n",
        "            predictions = self.predict(X=X)\n",
        "            for j in range(X.shape[0]):\n",
        "                if predictions[j] != y[j]:\n",
        "                    missClassifiedIndexes.append(j)\n",
        "            learner_error = (np.sum(self.samples_weights[missClassifiedIndexes])) / np.sum(self.samples_weights)        \n",
        "            # Compute learner weight using SAMME algorithm\n",
        "            self.learner_weights[i] = 0.5*np.log((1 - learner_error) / learner_error)\n",
        "            if learner_error >= 1 - (1 / n_classes):\n",
        "                self.learner_weights[i] = 0\n",
        "\n",
        "            # Increase the weights of misclassified samples\n",
        "            # for index, weigth in enumerate(self.samples_weights):\n",
        "                # if index in missClassifiedIndexes:\n",
        "                    # self.samples_weights[index] += self.weigh_increase_ratio\n",
        "            # self.samples_weights = self.samples_weights / (np.sum(self.samples_weights))       \n",
        "\n",
        "\n",
        "            for idx in missClassifiedIndexes:\n",
        "                self.samples_weights[idx] *= np.exp(self.learner_weights[i])\n",
        "\n",
        "            # Normalize the sample weights\n",
        "            self.samples_weights /= np.sum(self.samples_weights) \n",
        "            # Save the current learner\n",
        "            # self.learners.append(learner)\n",
        "            # self.learner_weights.append(learner_weight)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Collect predictions from each learner\n",
        "        # predictionsOfLearners = []\n",
        "        # for learner in self.learners:\n",
        "        #     if learner != None:\n",
        "        #         predictionsOfLearners.append(learner.predict(X))\n",
        "        # predictionsOfLearners = np.array(predictionsOfLearners)\n",
        "        # prediction = np.empty(X.shape[0])        \n",
        "        # for i in range(X.shape[0]):\n",
        "        #     labels = np.unique(predictionsOfLearners[:, i])\n",
        "        #     votes = {label : 0 for label in labels}\n",
        "        #     for j in range(len(predictionsOfLearners[:, i])):\n",
        "        #         for label in labels:\n",
        "        #             if predictionsOfLearners[j, i] == label:\n",
        "        #                 votes[label] += self.learner_weights[j]\n",
        "        #     finalPrediction = max(votes, key=votes.get)\n",
        "        #     prediction[i] = self.label_encoder.inverse_transform(np.array([finalPrediction]))\n",
        "\n",
        "        # return prediction\n",
        "\n",
        "        # def predict(self, X):\n",
        "        predictionsOfLearners = []\n",
        "        for learner in self.learners:\n",
        "            if learner is not None:\n",
        "                predictionsOfLearners.append(learner.predict(X))\n",
        "        predictionsOfLearners = np.array(predictionsOfLearners)\n",
        "\n",
        "        prediction = np.zeros(X.shape[0], dtype=int)\n",
        "\n",
        "        for i in range(X.shape[0]):\n",
        "            labels = np.unique(predictionsOfLearners[:, i])\n",
        "            votes = {label: 0 for label in labels}\n",
        "            for j in range(len(predictionsOfLearners)):\n",
        "                for label in labels:\n",
        "                    if predictionsOfLearners[j, i] == label:\n",
        "                        votes[label] += self.learner_weights[j]\n",
        "    \n",
        "            finalPrediction = max(votes, key=votes.get)\n",
        "            prediction[i] = finalPrediction\n",
        "        return self.label_encoder.inverse_transform(prediction)\n",
        "\n",
        "\n",
        "        # labels = np.unique(predictions)\n",
        "        # votes = {label : 0 for label in labels}\n",
        "        # for i in range(len(predictions)):\n",
        "            # for label in labels:\n",
        "                # if predictions[0][i] == label:\n",
        "                    # votes[label] += self.learner_weights[i]\n",
        "        \n",
        "        # # Weighted vote for each sample's prediction across all learners\n",
        "        # final_prediction = max(votes, key=votes.get)\n",
        "        # Final prediction is the one with the highest weighted vote\n",
        "        # return self.label_encoder.inverse_transform(np.array([final_prediction]))\n",
        "        # Convert back to original class labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]]\n",
            "[1 5 9]\n"
          ]
        }
      ],
      "source": [
        "def fit(self, X, y):\n",
        "        Y = self.label_encoder.fit_transform(y=y)\n",
        "        n_classes = len(np.unique(Y))\n",
        "        indexes = np.arange(X.shape[0])\n",
        "        self.samples_weights = (1/X.shape[0]) * np.ones(X.shape[0] ,dtype=float)\n",
        "        for i in range(self.n_estimators):\n",
        "            self.learners[i] = self.base_estimator\n",
        "            training_indexes = np.random.choice(indexes, indexes.shape[0], replace=True, p=self.samples_weights)\n",
        "            self.learners[i].fit(X[training_indexes], Y[training_indexes])\n",
        "            missClassifiedIndexes = []\n",
        "            predictions = self.predict(X=X)\n",
        "            for j in range(X.shape[0]):\n",
        "                if predictions[j] != y[j]:\n",
        "                    missClassifiedIndexes.append(j)\n",
        "            learner_error = (np.sum(self.samples_weights[missClassifiedIndexes])) / np.sum(self.samples_weights)        \n",
        "            self.learner_weights[i] = 0.5*np.log((1 - learner_error) / learner_error)\n",
        "            if learner_error >= 1 - (1 / n_classes):\n",
        "                self.learner_weights[i] = 0\n",
        "            # Increase the weights of misclassified samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "3                4.6               3.1                1.5               0.2   \n",
              "4                5.0               3.6                1.4               0.2   \n",
              "\n",
              "   target  \n",
              "0     0.0  \n",
              "1     0.0  \n",
              "2     0.0  \n",
              "3     0.0  \n",
              "4     0.0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df.iloc[:, :-1].to_numpy(), df.iloc[:, -1].to_numpy(), test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = SimpleMultiClassBoosting()\n",
        "m.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2.,\n",
              "       1., 1., 2., 1., 1., 1., 2., 2., 2., 2., 2., 1., 1.])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction = m.predict(X_test)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        10\n",
            "         1.0       0.41      1.00      0.58         9\n",
            "         2.0       1.00      0.73      0.84        11\n",
            "\n",
            "    accuracy                           0.57        30\n",
            "   macro avg       0.47      0.58      0.47        30\n",
            "weighted avg       0.49      0.57      0.48        30\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\javadpsk\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\javadpsk\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\javadpsk\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, prediction))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
