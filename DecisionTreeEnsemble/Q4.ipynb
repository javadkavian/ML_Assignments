{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "41ByKBEm2FFE"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = 0.1*np.ones(10,dtype=float)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "80eGYDq72Icw"
      },
      "outputs": [],
      "source": [
        "class SimpleMultiClassBoosting(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, base_estimator=None, n_estimators=50, weight_increase_ratio = 0.5):\n",
        "        self.base_estimator = base_estimator if base_estimator is not None else DecisionTreeClassifier(max_depth=1)\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learners = np.empty(n_estimators, dtype=object)\n",
        "        self.learner_weights = np.empty(n_estimators, dtype=float)\n",
        "        self.samples_weights = None\n",
        "        self.weigh_increase_ratio = weight_increase_ratio\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Convert labels to [0, n_classes-1]\n",
        "        Y = self.label_encoder.fit_transform(y=y)\n",
        "        n_classes = np.unique(Y)\n",
        "        indexes = np.arange(X.shape[0])\n",
        "        # Initialize weights uniformly\n",
        "        self.samples_weights = (1/X.shape[0]) * np.ones(X.shape[0] ,dtype=float)\n",
        "        for i in range(self.n_estimators):\n",
        "            self.learners[i] = self.base_estimator\n",
        "            training_indexes = np.random.choice(indexes, indexes.shape[0], replace=True, p=self.samples_weights)\n",
        "            self.learners[i].fit(X[training_indexes], Y[training_indexes])\n",
        "            # Compute weighted error rate (misclassification rate)\n",
        "            missClassifiedIndexes = []\n",
        "            predictions = self.predict(X=X)\n",
        "            print(predictions)\n",
        "            for i in range(X.shape[0]):\n",
        "                if predictions[i] != y[i]:\n",
        "                    missClassifiedIndexes.append(i)\n",
        "            learner_error = (np.sum(self.samples_weights[missClassifiedIndexes])) / np.sum(self.samples_weights)        \n",
        "\n",
        "            # Compute learner weight using SAMME algorithm\n",
        "            self.learner_weights[i] = 0.5*np.log((1 - learner_error) / learner_error)\n",
        "            if learner_error >= 1 - (1 / n_classes):\n",
        "                self.learner_weights[i] = 0\n",
        "\n",
        "            # Increase the weights of misclassified samples\n",
        "            for index, weigth in enumerate(self.samples_weights):\n",
        "                if index in missClassifiedIndexes:\n",
        "                    self.samples_weights[index] += self.weigh_increase_ratio\n",
        "\n",
        "            self.samples_weights = self.samples_weights / (np.sum(self.samples_weights))        \n",
        "            # Save the current learner\n",
        "            # self.learners.append(learner)\n",
        "            # self.learner_weights.append(learner_weight)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Collect predictions from each learner\n",
        "        predictions = []\n",
        "        for learner in self.learners:\n",
        "            if learner != None:\n",
        "                predictions.append(learner.predict(X))\n",
        "        print(predictions.shape)\n",
        "        # labels = np.unique(predictions)\n",
        "        # votes = {label : 0 for label in labels}\n",
        "        # for i in range(len(predictions)):\n",
        "        #     for label in labels:\n",
        "        #         if predictions[0][i] == label:\n",
        "        #             votes[label] += self.learner_weights[i]\n",
        "        \n",
        "        # # Weighted vote for each sample's prediction across all learners\n",
        "        # final_prediction = max(votes, key=votes.get)\n",
        "        # Final prediction is the one with the highest weighted vote\n",
        "        return self.label_encoder.inverse_transform(np.array([final_prediction]))\n",
        "        # Convert back to original class labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "3                4.6               3.1                1.5               0.2   \n",
              "4                5.0               3.6                1.4               0.2   \n",
              "\n",
              "   target  \n",
              "0     0.0  \n",
              "1     0.0  \n",
              "2     0.0  \n",
              "3     0.0  \n",
              "4     0.0  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df.iloc[:, :-1].to_numpy(), df.iloc[:, -1].to_numpy(), test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[62], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m m \u001b[38;5;241m=\u001b[39m SimpleMultiClassBoosting()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[61], line 24\u001b[0m, in \u001b[0;36mSimpleMultiClassBoosting.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Compute weighted error rate (misclassification rate)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m missClassifiedIndexes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 24\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
            "Cell \u001b[1;32mIn[61], line 52\u001b[0m, in \u001b[0;36mSimpleMultiClassBoosting.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m learner \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(learner\u001b[38;5;241m.\u001b[39mpredict(X))\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# labels = np.unique(predictions)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# votes = {label : 0 for label in labels}\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# for i in range(len(predictions)):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# final_prediction = max(votes, key=votes.get)\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Final prediction is the one with the highest weighted vote\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_encoder\u001b[38;5;241m.\u001b[39minverse_transform(np\u001b[38;5;241m.\u001b[39marray([final_prediction]))\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "m = SimpleMultiClassBoosting()\n",
        "m.fit(X_train, Y_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
